{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "415c9925",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:56:45.970710Z",
     "iopub.status.busy": "2022-05-25T04:56:45.970100Z",
     "iopub.status.idle": "2022-05-25T04:56:46.045515Z",
     "shell.execute_reply": "2022-05-25T04:56:46.044780Z"
    },
    "papermill": {
     "duration": 0.09206,
     "end_time": "2022-05-25T04:56:46.047571",
     "exception": false,
     "start_time": "2022-05-25T04:56:45.955511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Valid Score: 0.8408\n",
    "Improved (Valid Score: 0.8320 --> 0.8408, Epoch: 3)\n",
    "\n",
    "Valid Score: 0.8464\n",
    "Improved (Valid Score: 0.8408 --> 0.8464, Epoch: 4)\n",
    "\n",
    "Valid Score: 0.8481\n",
    "Improved (Valid Score: 0.8464 --> 0.8481, Epoch: 5)\n",
    "\n",
    "Valid Score: 0.8488\n",
    "Improved (Valid Score: 0.8481 --> 0.8488, Epoch: 6)\n",
    "\n",
    "Valid Score: 0.8514\n",
    "Improved (Valid Score: 0.8488 --> 0.8514, Epoch: 7)\n",
    "\n",
    "Valid Score: 0.8529\n",
    "Improved (Valid Score: 0.8514 --> 0.8529, Epoch: 8)\n",
    "\n",
    "Valid Score: 0.8532\n",
    "Improved (Valid Score: 0.8529 --> 0.8532, Epoch: 9)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # RTX 2080 Ti\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # RTX 3090\n",
    "\n",
    "data_dir = Path('/workspace/Kaggle/AI4Code')\n",
    "# data_dir = Path('../input/AI4Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc3f2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GeForce RTX 2080 Ti']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_gpus = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n",
    "available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52adc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 8\n",
    "code_max_len = 23\n",
    "md_max_len = 64\n",
    "total_max_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26bd5cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:56:46.074812Z",
     "iopub.status.busy": "2022-05-25T04:56:46.074362Z",
     "iopub.status.idle": "2022-05-25T04:56:46.152518Z",
     "shell.execute_reply": "2022-05-25T04:56:46.151166Z"
    },
    "papermill": {
     "duration": 0.093574,
     "end_time": "2022-05-25T04:56:46.154111",
     "exception": false,
     "start_time": "2022-05-25T04:56:46.060537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 269.96it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_notebook(path):\n",
    "    return (pd.read_json(path,\n",
    "                         dtype={\n",
    "                             'cell_type': 'category',\n",
    "                             'source': 'str'\n",
    "                         }).assign(id=path.stem).rename_axis('cell_id'))\n",
    "\n",
    "\n",
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "test_df = (pd.concat(notebooks_test).set_index(\n",
    "    'id',\n",
    "    append=True).swaplevel().sort_index(level='id',\n",
    "                                        sort_remaining=False)).reset_index()\n",
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ecd5278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:56:46.183664Z",
     "iopub.status.busy": "2022-05-25T04:56:46.183096Z",
     "iopub.status.idle": "2022-05-25T04:56:46.200914Z",
     "shell.execute_reply": "2022-05-25T04:56:46.200266Z"
    },
    "papermill": {
     "duration": 0.033865,
     "end_time": "2022-05-25T04:56:46.202511",
     "exception": false,
     "start_time": "2022-05-25T04:56:46.168646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>c6cd22db</td>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>1372ae9b</td>\n",
       "      <td>code</td>\n",
       "      <td>numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>90ed07ab</td>\n",
       "      <td>code</td>\n",
       "      <td>def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>7f388a41</td>\n",
       "      <td>code</td>\n",
       "      <td># Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>d3f5c397</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We have 177 rows with missing `Age` and 687 rows with missing `Cabin`</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02</td>\n",
       "      <td>code</td>\n",
       "      <td>sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>d22526d1</td>\n",
       "      <td>code</td>\n",
       "      <td>types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>3ae7ece3</td>\n",
       "      <td>code</td>\n",
       "      <td>#correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>eb293dfc</td>\n",
       "      <td>markdown</td>\n",
       "      <td>automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id   cell_id cell_type                                                                                                                   source  rank      pred\n",
       "0   0009d135ece78d  ddfd239c      code  import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...     0  0.142857\n",
       "1   0009d135ece78d  c6cd22db      code                                              df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf     1  0.285714\n",
       "2   0009d135ece78d  1372ae9b      code  numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...     2  0.428571\n",
       "3   0009d135ece78d  90ed07ab      code  def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...     3  0.571429\n",
       "4   0009d135ece78d  7f388a41      code  # Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...     4  0.714286\n",
       "..             ...       ...       ...                                                                                                                      ...   ...       ...\n",
       "84  0010a919d60e4f  d3f5c397  markdown                                                    We have 177 rows with missing `Age` and 687 rows with missing `Cabin`    34  1.000000\n",
       "85  0028856e09c5b7  012c9d02      code                                                                  sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size     0  0.333333\n",
       "86  0028856e09c5b7  d22526d1      code   types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...     1  0.666667\n",
       "87  0028856e09c5b7  3ae7ece3      code  #correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....     2  1.000000\n",
       "88  0028856e09c5b7  eb293dfc  markdown  automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...     0  1.000000\n",
       "\n",
       "[89 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e76f8888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:56:46.233385Z",
     "iopub.status.busy": "2022-05-25T04:56:46.232932Z",
     "iopub.status.idle": "2022-05-25T04:56:46.247042Z",
     "shell.execute_reply": "2022-05-25T04:56:46.246375Z"
    },
    "papermill": {
     "duration": 0.03123,
     "end_time": "2022-05-25T04:56:46.248708",
     "exception": false,
     "start_time": "2022-05-25T04:56:46.217478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional code cells\n",
    "def clean_code(cell):\n",
    "    return str(cell).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "\n",
    "def sample_cells(cells, n):\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if n >= len(cells):\n",
    "        return [cell[:200] for cell in cells]\n",
    "    else:\n",
    "        results = []\n",
    "        step = len(cells) / n\n",
    "        idx = 0\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            results.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        assert cells[0] in results\n",
    "        if cells[-1] not in results:\n",
    "            results[-1] = cells[-1]\n",
    "        return results\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = dict()\n",
    "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
    "    for idx, sub_df in tqdm(df.groupby(\"id\")):\n",
    "        features[idx] = dict()\n",
    "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
    "        total_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df.source.values, 20)\n",
    "        features[idx][\"total_code\"] = total_code\n",
    "        features[idx][\"total_md\"] = total_md\n",
    "        features[idx][\"codes\"] = codes\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f742131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:56:46.278855Z",
     "iopub.status.busy": "2022-05-25T04:56:46.278447Z",
     "iopub.status.idle": "2022-05-25T04:56:46.292385Z",
     "shell.execute_reply": "2022-05-25T04:56:46.291722Z"
    },
    "papermill": {
     "duration": 0.031401,
     "end_time": "2022-05-25T04:56:46.294472",
     "exception": false,
     "start_time": "2022-05-25T04:56:46.263071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1037.81it/s]\n"
     ]
    }
   ],
   "source": [
    "test_fts = get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1890607f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:56:46.326917Z",
     "iopub.status.busy": "2022-05-25T04:56:46.326521Z",
     "iopub.status.idle": "2022-05-25T04:56:52.735236Z",
     "shell.execute_reply": "2022-05-25T04:56:52.734528Z"
    },
    "papermill": {
     "duration": 6.427299,
     "end_time": "2022-05-25T04:56:52.737541",
     "exception": false,
     "start_time": "2022-05-25T04:56:46.310242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        self.top = nn.Linear(769, 1)\n",
    "\n",
    "    def forward(self, ids, mask, fts):\n",
    "        x = self.model(ids, mask)[0]\n",
    "        x = self.top(torch.cat((x[:, 0, :], fts), 1))\n",
    "        return x\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class MarkdownDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, model_name_or_path, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(row.source,\n",
    "                                            None,\n",
    "                                            add_special_tokens=True,\n",
    "                                            max_length=self.md_max_len,\n",
    "                                            padding=\"max_length\",\n",
    "                                            return_token_type_ids=True,\n",
    "                                            truncation=True)\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(x) for x in self.fts[row.id][\"codes\"]],\n",
    "            add_special_tokens=True,\n",
    "            max_length=code_max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True)\n",
    "        n_md = self.fts[row.id][\"total_md\"]\n",
    "        n_code = self.fts[row.id][\"total_md\"]\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [\n",
    "                self.tokenizer.pad_token_id,\n",
    "            ] * (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [\n",
    "                self.tokenizer.pad_token_id,\n",
    "            ] * (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "\n",
    "        return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c03f1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:56:52.788811Z",
     "iopub.status.busy": "2022-05-25T04:56:52.788101Z",
     "iopub.status.idle": "2022-05-25T04:56:52.801369Z",
     "shell.execute_reply": "2022-05-25T04:56:52.800782Z"
    },
    "papermill": {
     "duration": 0.0409,
     "end_time": "2022-05-25T04:56:52.803392",
     "exception": false,
     "start_time": "2022-05-25T04:56:52.762492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "\n",
    "def predict(model_path, ckpt_path):\n",
    "    model = MarkdownModel(model_path)\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(ckpt_path))\n",
    "    test_df[\"pct_rank\"] = 0\n",
    "    test_ds = MarkdownDataset(\n",
    "        test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True),\n",
    "        md_max_len=md_max_len,\n",
    "        total_max_len=total_max_len,\n",
    "        model_name_or_path=model_path,\n",
    "        fts=test_fts)\n",
    "    test_loader = DataLoader(test_ds,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=num_workers,\n",
    "                             pin_memory=False,\n",
    "                             drop_last=False)\n",
    "    _, y_test = validate(model, test_loader)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0876cb69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:56:52.855822Z",
     "iopub.status.busy": "2022-05-25T04:56:52.855407Z",
     "iopub.status.idle": "2022-05-25T04:56:52.858305Z",
     "shell.execute_reply": "2022-05-25T04:56:52.857750Z"
    },
    "papermill": {
     "duration": 0.032699,
     "end_time": "2022-05-25T04:56:52.862869",
     "exception": false,
     "start_time": "2022-05-25T04:56:52.830170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_path = \"../input/huggingface-bert-variants/distilbert-base-cased/distilbert-base-cased\"\n",
    "# ckpt_path = \"../input/ai4codemodels/model.bin\"\n",
    "# y_test_1 = predict(model_path, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f64e77dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:56:52.912833Z",
     "iopub.status.busy": "2022-05-25T04:56:52.912594Z",
     "iopub.status.idle": "2022-05-25T04:57:10.792427Z",
     "shell.execute_reply": "2022-05-25T04:57:10.791619Z"
    },
    "papermill": {
     "duration": 17.907618,
     "end_time": "2022-05-25T04:57:10.794877",
     "exception": false,
     "start_time": "2022-05-25T04:56:52.887259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/codebert-base-mlm were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = \"microsoft/codebert-base-mlm\"\n",
    "ckpt_path = data_dir / f\"outputs/codebert-base-mlm-v1/model_best_1epochs_0.8320.bin\"\n",
    "\n",
    "# model_path = \"../input/codebert-base/codebert-base/\"\n",
    "# ckpt_path = \"../input/ai4codemodelspublic/model.bin\"\n",
    "\n",
    "y_test_2 = predict(model_path, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0062ceb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:57:10.879188Z",
     "iopub.status.busy": "2022-05-25T04:57:10.878836Z",
     "iopub.status.idle": "2022-05-25T04:57:10.883386Z",
     "shell.execute_reply": "2022-05-25T04:57:10.882632Z"
    },
    "papermill": {
     "duration": 0.057441,
     "end_time": "2022-05-25T04:57:10.887981",
     "exception": false,
     "start_time": "2022-05-25T04:57:10.830540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_test = (y_test_1 + y_test_2)/2\n",
    "y_test = y_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f40f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:57:10.960407Z",
     "iopub.status.busy": "2022-05-25T04:57:10.960083Z",
     "iopub.status.idle": "2022-05-25T04:57:10.968726Z",
     "shell.execute_reply": "2022-05-25T04:57:10.968025Z"
    },
    "papermill": {
     "duration": 0.041751,
     "end_time": "2022-05-25T04:57:10.971308",
     "exception": false,
     "start_time": "2022-05-25T04:57:10.929557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26a61da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:57:11.036828Z",
     "iopub.status.busy": "2022-05-25T04:57:11.036519Z",
     "iopub.status.idle": "2022-05-25T04:57:11.060834Z",
     "shell.execute_reply": "2022-05-25T04:57:11.059958Z"
    },
    "papermill": {
     "duration": 0.060519,
     "end_time": "2022-05-25T04:57:11.063678",
     "exception": false,
     "start_time": "2022-05-25T04:57:11.003159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>0a226b6a ddfd239c 8cb8d28a c6cd22db 1372ae9b e25aa9bd 90ed07ab ba55e576 39e937ec f9893819 7f388a41 2843a25a 06dbf8cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>23607d04 b7578789 aafc3d23 80e077ec bbff12d4 584f6568 b190ebb4 d3f5c397 ed415c3c 8ce62db4 322850af 5115ebe5 5e8c5e7e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02 eb293dfc d22526d1 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                               cell_order\n",
       "0  0009d135ece78d     0a226b6a ddfd239c 8cb8d28a c6cd22db 1372ae9b e25aa9bd 90ed07ab ba55e576 39e937ec f9893819 7f388a41 2843a25a 06dbf8cf\n",
       "1  0010483c12ba9b                                7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d\n",
       "2  0010a919d60e4f  23607d04 b7578789 aafc3d23 80e077ec bbff12d4 584f6568 b190ebb4 d3f5c397 ed415c3c 8ce62db4 322850af 5115ebe5 5e8c5e7e...\n",
       "3  0028856e09c5b7                                                                                      012c9d02 eb293dfc d22526d1 3ae7ece3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5ce871e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T04:57:11.138508Z",
     "iopub.status.busy": "2022-05-25T04:57:11.138256Z",
     "iopub.status.idle": "2022-05-25T04:57:11.146311Z",
     "shell.execute_reply": "2022-05-25T04:57:11.145703Z"
    },
    "papermill": {
     "duration": 0.046216,
     "end_time": "2022-05-25T04:57:11.148539",
     "exception": false,
     "start_time": "2022-05-25T04:57:11.102323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf04506",
   "metadata": {
    "papermill": {
     "duration": 0.028064,
     "end_time": "2022-05-25T04:57:11.204881",
     "exception": false,
     "start_time": "2022-05-25T04:57:11.176817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36.441188,
   "end_time": "2022-05-25T04:57:14.435693",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-25T04:56:37.994505",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
